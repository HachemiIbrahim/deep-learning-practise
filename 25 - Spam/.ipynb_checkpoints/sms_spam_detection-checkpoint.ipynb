{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8eef654-6b56-405f-ae82-2f7eb266b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "252d3f1a-3973-497b-aba3-52f5b2d5848c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message   spam\n",
       "0  Go until jurong point, crazy.. Available only ...  False\n",
       "1                      Ok lar... Joking wif u oni...  False\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   True\n",
       "3  U dun say so early hor... U c already then say...  False\n",
       "4  Nah I don't think he goes to usf, he lives aro...  False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/SMSSpamCollection\", sep=\"\\t\", names=[\"type\", \"message\"])\n",
    "df[\"spam\"] = df[\"type\"] == \"spam\"\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086eff4a-009d-4e0b-a557-2f26b9bee354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAM messages:\n",
      "747\n"
     ]
    }
   ],
   "source": [
    "print(\"SPAM messages:\")\n",
    "print(len(df[df[\"spam\"] == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7676ffbe-2722-4761-8d20-d28d6e947dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAM messages:\n",
      "4825\n"
     ]
    }
   ],
   "source": [
    "print(\"SPAM messages:\")\n",
    "print(len(df[df[\"spam\"] == False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa88ceb-00fd-4256-98f9-35aecc8266f4",
   "metadata": {},
   "source": [
    "# Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c3e7dfe-fb4b-4504-bd61-d5e9828f0bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/SMSSpamCollection\", \n",
    "                 sep=\"\\t\", \n",
    "                 names=[\"type\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb1ce81-ff49-4bc8-9279-f850826ddddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"spam\"] = df[\"type\"] == \"spam\"\n",
    "df.drop(\"type\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672f470a-155a-4f44-a61d-d95f1c8da8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22312110-a969-49bc-b997-e39f1905a64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 12 stored elements and shape (1, 1000)>\n",
      "  Coords\tValues\n",
      "  (0, 347)\t1\n",
      "  (0, 886)\t1\n",
      "  (0, 656)\t1\n",
      "  (0, 202)\t1\n",
      "  (0, 88)\t1\n",
      "  (0, 608)\t1\n",
      "  (0, 427)\t1\n",
      "  (0, 359)\t1\n",
      "  (0, 972)\t1\n",
      "  (0, 828)\t1\n",
      "  (0, 356)\t1\n",
      "  (0, 920)\t1\n",
      "update\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = CountVectorizer(max_features=1000)\n",
    "messages = cv.fit_transform(df[\"message\"])\n",
    "print(messages[0, :])\n",
    "print(cv.get_feature_names_out()[888])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a4b3b3b-c566-4ed8-80f4-6327393597b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1198, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0925, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0832, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0793, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0701, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0613, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0550, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0538, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0486, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0477, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0448, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 0.0187],\n",
      "        [-0.0126],\n",
      "        [ 0.9056],\n",
      "        ...,\n",
      "        [-0.0022],\n",
      "        [ 0.1949],\n",
      "        [ 0.0342]])\n",
      "tensor(-0.6876)\n",
      "tensor(1.5568)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = torch.tensor(messages.todense(), dtype=torch.float32)\n",
    "y = torch.tensor(df[\"spam\"], dtype=torch.float32)\\\n",
    "        .reshape((-1, 1))\n",
    "\n",
    "model = nn.Linear(1000, 1)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = loss_fn(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 100 == 0: \n",
    "        print(loss)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "    print(y_pred)\n",
    "    print(y_pred.min())\n",
    "    print(y_pred.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c117981a-a522-4145-9fd6-e38c514fdd68",
   "metadata": {},
   "source": [
    "## BCE with Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b47860d-cfec-47c7-afe4-8e23f9644fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:39: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "<>:39: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.2234, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1632, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1360, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1201, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1093, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1015, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0954, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0906, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0865, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "accuracy: 0.9768\n",
      "sensitivity: 0.8487\n",
      "specificity: 0.9967\n",
      "precision: 0.9754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_25384\\4169624178.py:39: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  print(\"precision:\" (y_pred[y_pred == 1] == y[y_pred == 1]).type(torch.float32).mean())\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mspecificity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspecificity\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprecision:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.type(torch.float32).mean()) \n",
      "\u001b[31mTypeError\u001b[39m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "model = nn.Linear(1000, 1)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02)\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = loss_fn(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 1000 == 0: \n",
    "        print(loss)\n",
    "\n",
    "# evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = (nn.functional.sigmoid(model(X)) > 0.5).type(torch.float32)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = (y_pred == y).type(torch.float32).mean()\n",
    "\n",
    "    # Sensitivity (recall for positives)\n",
    "    sensitivity = (y_pred[y == 1] == y[y == 1]).type(torch.float32).mean()\n",
    "\n",
    "    # Specificity (recall for negatives)\n",
    "    specificity = (y_pred[y == 0] == y[y == 0]).type(torch.float32).mean()\n",
    "\n",
    "    # Precision (of predicted positives, how many are correct)\n",
    "    precision = (y_pred[y_pred == 1] == y[y_pred == 1]).type(torch.float32).mean()\n",
    "\n",
    "    # Print nicely\n",
    "    print(f\"accuracy: {accuracy:.4f}\")\n",
    "    print(f\"sensitivity: {sensitivity:.4f}\")\n",
    "    print(f\"specificity: {specificity:.4f}\")\n",
    "    print(f\"precision: {precision:.4f}\")\n",
    "\n",
    "    print(\"precision:\" (y_pred[y_pred == 1] == y[y_pred == 1]).type(torch.float32).mean()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
