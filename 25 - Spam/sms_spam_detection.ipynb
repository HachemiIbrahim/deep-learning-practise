{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8eef654-6b56-405f-ae82-2f7eb266b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "252d3f1a-3973-497b-aba3-52f5b2d5848c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message   spam\n",
       "0  Go until jurong point, crazy.. Available only ...  False\n",
       "1                      Ok lar... Joking wif u oni...  False\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   True\n",
       "3  U dun say so early hor... U c already then say...  False\n",
       "4  Nah I don't think he goes to usf, he lives aro...  False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/SMSSpamCollection\", sep=\"\\t\", names=[\"type\", \"message\"])\n",
    "df[\"spam\"] = df[\"type\"] == \"spam\"\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086eff4a-009d-4e0b-a557-2f26b9bee354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAM messages:\n",
      "747\n"
     ]
    }
   ],
   "source": [
    "print(\"SPAM messages:\")\n",
    "print(len(df[df[\"spam\"] == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7676ffbe-2722-4761-8d20-d28d6e947dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAM messages:\n",
      "4825\n"
     ]
    }
   ],
   "source": [
    "print(\"SPAM messages:\")\n",
    "print(len(df[df[\"spam\"] == False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa88ceb-00fd-4256-98f9-35aecc8266f4",
   "metadata": {},
   "source": [
    "# Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c3e7dfe-fb4b-4504-bd61-d5e9828f0bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/SMSSpamCollection\", \n",
    "                 sep=\"\\t\", \n",
    "                 names=[\"type\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb1ce81-ff49-4bc8-9279-f850826ddddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"spam\"] = df[\"type\"] == \"spam\"\n",
    "df.drop(\"type\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "672f470a-155a-4f44-a61d-d95f1c8da8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22312110-a969-49bc-b997-e39f1905a64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 12 stored elements and shape (1, 1000)>\n",
      "  Coords\tValues\n",
      "  (0, 347)\t1\n",
      "  (0, 886)\t1\n",
      "  (0, 656)\t1\n",
      "  (0, 202)\t1\n",
      "  (0, 88)\t1\n",
      "  (0, 608)\t1\n",
      "  (0, 427)\t1\n",
      "  (0, 359)\t1\n",
      "  (0, 972)\t1\n",
      "  (0, 828)\t1\n",
      "  (0, 356)\t1\n",
      "  (0, 920)\t1\n",
      "update\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = CountVectorizer(max_features=1000)\n",
    "messages = cv.fit_transform(df[\"message\"])\n",
    "print(messages[0, :])\n",
    "print(cv.get_feature_names_out()[888])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a4b3b3b-c566-4ed8-80f4-6327393597b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1498, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1258, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1124, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1037, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0919, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0553, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0485, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0477, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0463, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0450, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0439, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0434, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0429, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0407, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0395, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0388, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0382, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0525],\n",
      "        [ 0.0098],\n",
      "        [ 0.8773],\n",
      "        ...,\n",
      "        [-0.0515],\n",
      "        [ 0.1715],\n",
      "        [ 0.0144]])\n",
      "tensor(-0.7010)\n",
      "tensor(1.5457)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = torch.tensor(messages.todense(), dtype=torch.float32)\n",
    "y = torch.tensor(df[\"spam\"], dtype=torch.float32)\\\n",
    "        .reshape((-1, 1))\n",
    "\n",
    "model = nn.Linear(1000, 1)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = loss_fn(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 100 == 0: \n",
    "        print(loss)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "    print(y_pred)\n",
    "    print(y_pred.min())\n",
    "    print(y_pred.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c117981a-a522-4145-9fd6-e38c514fdd68",
   "metadata": {},
   "source": [
    "## BCE with Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b47860d-cfec-47c7-afe4-8e23f9644fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6968, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:39: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "<>:39: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2251, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1640, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1366, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1205, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1097, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1018, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0957, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0908, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0867, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_21984\\4169624178.py:39: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  print(\"precision:\" (y_pred[y_pred == 1] == y[y_pred == 1]).type(torch.float32).mean())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9772\n",
      "sensitivity: 0.8514\n",
      "specificity: 0.9967\n",
      "precision: 0.9755\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mspecificity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspecificity\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprecision:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.type(torch.float32).mean()) \n",
      "\u001b[31mTypeError\u001b[39m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "model = nn.Linear(1000, 1)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02)\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = loss_fn(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 1000 == 0: \n",
    "        print(loss)\n",
    "\n",
    "# evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = (nn.functional.sigmoid(model(X)) > 0.5).type(torch.float32)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = (y_pred == y).type(torch.float32).mean()\n",
    "\n",
    "    # Sensitivity (recall for positives)\n",
    "    sensitivity = (y_pred[y == 1] == y[y == 1]).type(torch.float32).mean()\n",
    "\n",
    "    # Specificity (recall for negatives)\n",
    "    specificity = (y_pred[y == 0] == y[y == 0]).type(torch.float32).mean()\n",
    "\n",
    "    # Precision (of predicted positives, how many are correct)\n",
    "    precision = (y_pred[y_pred == 1] == y[y_pred == 1]).type(torch.float32).mean()\n",
    "\n",
    "    # Print nicely\n",
    "    print(f\"accuracy: {accuracy:.4f}\")\n",
    "    print(f\"sensitivity: {sensitivity:.4f}\")\n",
    "    print(f\"specificity: {specificity:.4f}\")\n",
    "    print(f\"precision: {precision:.4f}\")\n",
    "\n",
    "    print(\"precision:\" (y_pred[y_pred == 1] == y[y_pred == 1]).type(torch.float32).mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e9e2c-a3e6-4b7f-a444-0b37c49ccf70",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aefee80-a9c1-40fc-8d39-b525bf22eed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6942, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.2218, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1604, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1325, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1159, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1047, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0964, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0899, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0847, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0803, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Evaluating on the training data\n",
      "accuracy: tensor(0.9809)\n",
      "sensitivity: tensor(0.9293)\n",
      "specificity: tensor(0.9891)\n",
      "precision: tensor(0.9308)\n",
      "Evaluating on the validation data\n",
      "accuracy: tensor(0.9767)\n",
      "sensitivity: tensor(0.9209)\n",
      "specificity: tensor(0.9846)\n",
      "precision: tensor(0.8951)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df = pd.read_csv(\"./data/SMSSpamCollection\", \n",
    "                 sep=\"\\t\", \n",
    "                 names=[\"type\", \"message\"])\n",
    "\n",
    "df[\"spam\"] = df[\"type\"] == \"spam\"\n",
    "df.drop(\"type\", axis=1, inplace=True)\n",
    "\n",
    "df_train = df.sample(frac=0.8, random_state=0)\n",
    "df_val = df.drop(index=df_train.index)\n",
    "\n",
    "cv = CountVectorizer(max_features=5000)\n",
    "messages_train = cv.fit_transform(df_train[\"message\"])\n",
    "messages_val = cv.transform(df_val[\"message\"])\n",
    "\n",
    "X_train = torch.tensor(messages_train.todense(), dtype=torch.float32)\n",
    "y_train = torch.tensor(df_train[\"spam\"].values, dtype=torch.float32)\\\n",
    "        .reshape((-1, 1))\n",
    "\n",
    "X_val = torch.tensor(messages_val.todense(), dtype=torch.float32)\n",
    "y_val = torch.tensor(df_val[\"spam\"].values, dtype=torch.float32)\\\n",
    "        .reshape((-1, 1))\n",
    "\n",
    "model = nn.Linear(5000, 1)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02)\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = loss_fn(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 1000 == 0: \n",
    "        print(loss)\n",
    "\n",
    "def evaluate_model(X, y): \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = nn.functional.sigmoid(model(X)) > 0.25\n",
    "        print(\"accuracy:\", (y_pred == y)\\\n",
    "            .type(torch.float32).mean())\n",
    "        \n",
    "        print(\"sensitivity:\", (y_pred[y == 1] == y[y == 1])\\\n",
    "            .type(torch.float32).mean())\n",
    "        \n",
    "        print(\"specificity:\", (y_pred[y == 0] == y[y == 0])\\\n",
    "            .type(torch.float32).mean())\n",
    "\n",
    "        print(\"precision:\", (y_pred[y_pred == 1] == y[y_pred == 1])\\\n",
    "            .type(torch.float32).mean()) \n",
    "        \n",
    "print(\"Evaluating on the training data\")\n",
    "evaluate_model(X_train, y_train)\n",
    "\n",
    "print(\"Evaluating on the validation data\")\n",
    "evaluate_model(X_val, y_val)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b8320-5b62-4530-b570-2373a0be236c",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ec31ef4-a761-4596-86ca-37cbc2bc0177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0517],\n",
      "        [0.5956],\n",
      "        [0.0130]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "custom_messages = cv.transform([\n",
    "    \"We have release a new product, do you want to buy it?\", \n",
    "    \"Winner! Great deal, call us to get this product for free\",\n",
    "    \"Tomorrow is my birthday, do you come to the party?\"\n",
    "])\n",
    "\n",
    "X_custom = torch.tensor(custom_messages.todense(), dtype=torch.float32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = nn.functional.sigmoid(model(X_custom))\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e506f4-8d0a-4f5c-85c8-617542c33c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
