{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3a316b-aee0-4492-9894-d94e4dd1f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e8d822-9f04-4b07-977c-3152f552d492",
   "metadata": {},
   "source": [
    "![alt text](./cnn.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6113045b-5b8c-465b-893f-9d573a96043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mnist_train = datasets.FashionMNIST(root='./data', download=True, train=True, transform=ToTensor())\n",
    "mnist_test = datasets.FashionMNIST(root='./data', download=True, train=False, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b69085-b956-43ad-bec9-26271602cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(mnist_train, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(mnist_test, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538e4239-3d37-49f6-ac95-ac92bb23beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 3, kernel_size=(3, 3), padding=1, padding_mode=\"reflect\"),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2352, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742b7be-6a07-4e10-96c8-d9ab920c1be3",
   "metadata": {},
   "source": [
    "- nn.Conv2d(1, 3, kernel_size=(3, 3), padding=1)\n",
    "\n",
    "Input: 1 channel (grayscale).\n",
    "\n",
    "Output: 3 channels (3 filters).\n",
    "\n",
    "Kernel: 3×3 filter, slides over the image to extract features.\n",
    "\n",
    "Padding keeps size = 28×28 after convolution.\n",
    "\n",
    "Now the image is shaped (3, 28, 28).\n",
    "\n",
    "- nn.ReLU()\n",
    "\n",
    "Adds non-linearity (so network can learn complex patterns).\n",
    "\n",
    "- nn.Flatten()\n",
    "\n",
    "Turns the (3, 28, 28) feature map into a flat vector.\n",
    "\n",
    "3×28×28=2352\n",
    "3×28×28=2352. That’s why the next layer has input size 2352.\n",
    "\n",
    "- nn.Linear(2352, 100)\n",
    "\n",
    "Fully connected layer: maps 2352 features → 100 features.\n",
    "\n",
    "- nn.ReLU()\n",
    "\n",
    "Another non-linearity.\n",
    "\n",
    "- nn.Linear(100, 10)\n",
    "\n",
    "Final classifier layer: 10 outputs (because Fashion-MNIST has 10 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7304e92c-9d1b-4d27-8408-8914dcba0170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image = mnist_train[0][0].reshape(1, 1, 28, 28)\n",
    "output = model(image)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c9e501d-e554-4809-8fe5-ea45c6688843",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fea28db-949d-4c84-9998-a579a4cc5e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918.5741228684783\n",
      "625.3834326155484\n",
      "554.5283737443388\n",
      "500.3174466062337\n",
      "464.851099755615\n",
      "428.3626783154905\n",
      "395.7108837836422\n",
      "368.4077425841242\n",
      "340.5217226119712\n",
      "314.1243452131748\n"
     ]
    }
   ],
   "source": [
    "for i in range(0 ,10):\n",
    "    model.train()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    for X, y in train_dataloader:\n",
    "        y = F.one_hot(y, num_classes=10).type(torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum+=loss.item()\n",
    "    print(loss_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b030252-6a09-4c3c-b5e3-01f23d7d4c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data: 0.8965\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    accurate = 0\n",
    "    total = 0\n",
    "    for X, y in test_dataloader:\n",
    "        outputs = nn.functional.softmax(model(X), dim=1) \n",
    "        correct_pred = (y == outputs.max(dim=1).indices)\n",
    "        total+=correct_pred.size(0)\n",
    "        accurate+=correct_pred.type(torch.int).sum().item()\n",
    "    print(\"Accuracy on validation data:\", accurate / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412e2d01-dcd8-49dc-80a2-d449c072b416",
   "metadata": {},
   "source": [
    "## MaxPooling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d4c74d-0af7-4290-8e8c-1b94f483650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 3, kernel_size=(3, 3), padding=1, padding_mode=\"reflect\"),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(588, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae573041-c9a2-47e3-ab34-0f83fc2acef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a68fefd-5b26-4fe1-8b3e-3259f0b7cfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088.2179971262813\n",
      "773.8737029209733\n",
      "666.1563119292259\n",
      "604.8004098087549\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m     loss = loss_fn(outputs, y)\n\u001b[32m     11\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     loss_sum+=loss.item()\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(loss_sum)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\pytorch\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:516\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    513\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\pytorch\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\pytorch\\env\\Lib\\site-packages\\torch\\optim\\adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\pytorch\\env\\Lib\\site-packages\\torch\\optim\\optimizer.py:149\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\pytorch\\env\\Lib\\site-packages\\torch\\optim\\adam.py:949\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\pytorch\\env\\Lib\\site-packages\\torch\\optim\\adam.py:533\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    531\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m         denom = \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    537\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    model.train()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    for X, y in train_dataloader:\n",
    "        y = F.one_hot(y, num_classes=10).type(torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum+=loss.item()\n",
    "    print(loss_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741db62e-064f-4b06-9f21-b58a5dee699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    accurate = 0\n",
    "    total = 0\n",
    "    for X, y in test_dataloader:\n",
    "        outputs = nn.functional.softmax(model(X), dim=1) \n",
    "        correct_pred = (y == outputs.max(dim=1).indices)\n",
    "        total+=correct_pred.size(0)\n",
    "        accurate+=correct_pred.type(torch.int).sum().item()\n",
    "    print(\"Accuracy on validation data:\", accurate / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b272cb-9975-4db3-96c6-011b13744797",
   "metadata": {},
   "source": [
    "## GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd50a1fd-a5f8-4f1f-bd46-0260e83ca43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce MX450\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())   # True\n",
    "print(torch.cuda.get_device_name(0))  # Name of your GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c9fbcd-556c-4e26-a8af-f31cd115fcb2",
   "metadata": {},
   "source": [
    "### Device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac76f254-1488-49bd-b3ca-3da73f33f919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda\n",
      "NVIDIA GeForce MX450\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee4db903-2db2-4c35-87fe-4d1041df4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 3, kernel_size=(3, 3), padding=1, padding_mode=\"reflect\"),\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(588, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 10)\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d27245f8-d8e1-49a0-9b72-baded3da1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deb63e7d-767d-4419-9a57-514052acfe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaxPool] Epoch 1 - Loss: 1053.0380\n",
      "[MaxPool] Epoch 2 - Loss: 733.0779\n",
      "[MaxPool] Epoch 3 - Loss: 650.6327\n",
      "[MaxPool] Epoch 4 - Loss: 599.4823\n",
      "[MaxPool] Epoch 5 - Loss: 558.6002\n",
      "[MaxPool] Epoch 6 - Loss: 522.0804\n",
      "[MaxPool] Epoch 7 - Loss: 496.1502\n",
      "[MaxPool] Epoch 8 - Loss: 471.9763\n",
      "[MaxPool] Epoch 9 - Loss: 451.2240\n",
      "[MaxPool] Epoch 10 - Loss: 431.9807\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "    print(f\"[MaxPool] Epoch {epoch} - Loss: {loss_sum:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21cc4dea-4abd-4f56-8340-722746d3b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaxPool] Accuracy on validation data: 0.8897\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    accurate = 0\n",
    "    total = 0\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        outputs = F.softmax(model(X), dim=1)\n",
    "        correct_pred = (y == outputs.argmax(dim=1))\n",
    "        total += y.size(0)\n",
    "        accurate += correct_pred.sum().item()\n",
    "    print(\"[MaxPool] Accuracy on validation data:\", accurate / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb478c13-3f89-46ad-99d8-f5c47fe45001",
   "metadata": {},
   "source": [
    "## more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7b1abae-ef73-4316-bbb0-5eb0621c7efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (2): Flatten(start_dim=1, end_dim=-1)\n",
      "  (3): Sequential(\n",
      "    (0): Linear(in_features=294, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Sequential(\n",
    "        nn.Conv2d(1, 3, kernel_size=(3, 3), padding=1, padding_mode=\"reflect\"),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.ReLU()\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Conv2d(3, 6, kernel_size=(3, 3), padding=1, padding_mode=\"reflect\"),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.ReLU(),\n",
    "    ),\n",
    "    nn.Flatten(),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(294, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 10)\n",
    "    )\n",
    ").to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35b128f4-0e8b-4b33-aefb-0c402e85d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e876ee73-673a-4bb5-8a54-2005605df488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113.313080072403\n",
      "756.3749868422747\n",
      "662.9428348839283\n",
      "609.2082643024623\n",
      "574.2079039029777\n",
      "548.4008865840733\n",
      "524.3564683329314\n",
      "502.0268983859569\n",
      "486.3244345188141\n",
      "467.8021500688046\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    model.train()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    for X, y in train_dataloader:\n",
    "        y = F.one_hot(y, num_classes=10).type(torch.float32).to(device)\n",
    "        X = X.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum+=loss.item()\n",
    "    print(loss_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bbf8098-38a4-4749-8add-3c3d3c77c74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data: 0.8881\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    accurate = 0\n",
    "    total = 0\n",
    "    for X, y in test_dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = nn.functional.softmax(model(X), dim=1) \n",
    "        correct_pred = (y == outputs.max(dim=1).indices)\n",
    "        total+=correct_pred.size(0)\n",
    "        accurate+=correct_pred.type(torch.int).sum().item()\n",
    "    print(\"Accuracy on validation data:\", accurate / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802bff3c-a9dd-4bf9-ab21-11637895e59c",
   "metadata": {},
   "source": [
    "## Larger CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d3be1cb-dc78-41b4-9739-e2b091be9c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=(3, 3), padding=1, padding_mode=\"reflect\"),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.ReLU()\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1, padding_mode=\"reflect\"),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.ReLU(),\n",
    "    ),\n",
    "    nn.Flatten(),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(64 * 7 * 7, 1000),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1000, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 10)\n",
    "    )\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "308af7c2-f6fd-461f-baf3-f4b67a9569c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f979883c-2620-49e4-890c-370b3d0017a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800.1645726002753\n",
      "506.5415538381785\n",
      "413.3224321035668\n",
      "347.1238796496764\n",
      "287.43498641671613\n",
      "236.00117878778838\n",
      "187.5386844757013\n",
      "154.37384290696355\n",
      "124.61289830028545\n",
      "104.9892877957027\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    model.train()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    for X, y in train_dataloader:\n",
    "        y = F.one_hot(y, num_classes=10).type(torch.float32).to(device)\n",
    "        X = X.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum+=loss.item()\n",
    "    print(loss_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0092aa6-e0e8-4b83-8e21-ba8e97e645cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data: 0.9201\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    accurate = 0\n",
    "    total = 0\n",
    "    for X, y in test_dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = nn.functional.softmax(model(X), dim=1) \n",
    "        correct_pred = (y == outputs.max(dim=1).indices)\n",
    "        total+=correct_pred.size(0)\n",
    "        accurate+=correct_pred.type(torch.int).sum().item()\n",
    "    print(\"Accuracy on validation data:\", accurate / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d09196-7346-4904-8dc3-ffe96d2d92ff",
   "metadata": {},
   "source": [
    "## applying dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53708309-3211-4ee4-9dd8-c45f047ec83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (2): Flatten(start_dim=1, end_dim=-1)\n",
      "  (3): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=(3, 3), padding=1, padding_mode=\"reflect\"),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1)\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1, padding_mode=\"reflect\"),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1)\n",
    "    ),\n",
    "    nn.Flatten(),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(64 * 7 * 7, 1000),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(1000, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(100, 10)\n",
    "    )\n",
    ").to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f9f5b30-fa27-45e6-a2a8-2e59c095142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da087963-0e01-4152-9df9-f1d00d42092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001.566509835422\n",
      "613.5317837782204\n",
      "519.0851547382772\n",
      "460.40099885314703\n",
      "419.17323758266866\n",
      "383.80130382440984\n",
      "344.9323789924383\n",
      "329.2082580961287\n",
      "302.02937741577625\n",
      "289.1371460594237\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    model.train()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    for X, y in train_dataloader:\n",
    "        y = F.one_hot(y, num_classes=10).type(torch.float32).to(device)\n",
    "        X = X.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum+=loss.item()\n",
    "    print(loss_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7c145ff-e39f-418a-bda1-cf03865b2314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data: 0.9252\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    accurate = 0\n",
    "    total = 0\n",
    "    for X, y in test_dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = nn.functional.softmax(model(X), dim=1) \n",
    "        correct_pred = (y == outputs.max(dim=1).indices)\n",
    "        total+=correct_pred.size(0)\n",
    "        accurate+=correct_pred.type(torch.int).sum().item()\n",
    "    print(\"Accuracy on validation data:\", accurate / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d7bc9e-c091-472d-87fb-c85dea324c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
