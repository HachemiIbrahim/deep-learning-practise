{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac5e464",
   "metadata": {},
   "source": [
    "## Training nueron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca3ad74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3bcd0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2ed789",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input: Temperature in °C\n",
    "X1 = torch.tensor([[10]], dtype=torch.float32) \n",
    "# Actual value: Temperature °F\n",
    "y1 = torch.tensor([[50]], dtype=torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c76bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input: Temperature in °C\n",
    "X2 = torch.tensor([[37.78]], dtype=torch.float32) \n",
    "# Actual value: Temperature °F\n",
    "y2 = torch.tensor([[100.0]], dtype=torch.float32) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a57b20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = nn.Linear(1, 1)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001) # this use Stochastic Gradient Descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91690d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.5720], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2abdc354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.4372], requires_grad=True)\n",
      "y1_pred = tensor([[5.9641]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training pass\n",
    "# Clear old gradients → predict → calculate error → compute gradients → update weights → check the result.\n",
    "optimizer.zero_grad() # clear old gradient\n",
    "outputs = model(X1) # predict\n",
    "loss = loss_fn(outputs, y1) # calculate loss\n",
    "loss.backward() # calculate gradient\n",
    "optimizer.step() # update weights\n",
    "\n",
    "print(model.bias)\n",
    "\n",
    "\n",
    "y1_pred = model(X1)\n",
    "print(\"y1_pred =\", y1_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05abcf",
   "metadata": {},
   "source": [
    "## training neuron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e09aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.6160], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[4.8578]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([nan], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan]], requires_grad=True)\n",
      "y1_pred = tensor([[nan]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10000):\n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X1)\n",
    "    loss = loss_fn(outputs, y1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X2)\n",
    "    loss = loss_fn(outputs, y2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 1000 == 0: \n",
    "        print(model.bias)\n",
    "        print(model.weight)\n",
    "\n",
    "y1_pred = model(X1)\n",
    "print(\"y1_pred =\", y1_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf12b64",
   "metadata": {},
   "source": [
    "## batch learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b08e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([\n",
    "    [10],\n",
    "    [37.78]\n",
    "] , dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10db6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.tensor([\n",
    "    [50],\n",
    "    [100]\n",
    "] , dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66a23d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = nn.Linear(1, 1)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d0515f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([12.4743], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.4109]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([13.4355], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.3809]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([14.3495], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.3523]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([15.2184], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.3251]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([16.0446], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.2992]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([16.8301], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.2746]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([17.5769], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.2513]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([18.2870], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.2290]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([18.9621], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.2079]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([19.6040], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.1878]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([20.2143], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.1687]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([20.7945], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.1506]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([21.3462], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.1333]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([21.8707], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.1169]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([22.3694], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.1013]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([22.8436], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.0864]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([23.2944], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.0723]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([23.7230], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.0589]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([24.1305], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.0462]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([24.5180], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.0340]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([24.8864], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.0225]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([25.2366], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.0116]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([25.5696], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.0011]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([25.8863], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.9912]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([26.1873], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.9818]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([26.4735], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.9728]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([26.7456], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.9643]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([27.0043], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.9562]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([27.2503], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.9485]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([27.4842], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.9412]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([27.7066], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.9343]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([27.9180], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.9276]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([28.1190], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.9214]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([28.3101], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.9154]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([28.4918], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.9097]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([28.6646], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.9043]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([28.8288], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8991]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([28.9850], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8943]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([29.1335], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8896]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([29.2747], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8852]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([29.4089], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8810]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([29.5365], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8770]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([29.6579], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8732]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([29.7732], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8696]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([29.8829], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8662]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([29.9872], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8629]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([30.0864], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8598]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([30.1806], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8568]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([30.2702], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8540]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([30.3555], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8514]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([30.4365], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8488]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([30.5135], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8464]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([30.5868], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8441]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([30.6564], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.8419]], requires_grad=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, Y)\n\u001b[0;32m      6\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m----> 7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\sgd.py:125\u001b[0m, in \u001b[0;36mSGD.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    119\u001b[0m momentum_buffer_list: List[Optional[Tensor]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    121\u001b[0m has_sparse_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    122\u001b[0m     group, params, grads, momentum_buffer_list\n\u001b[0;32m    123\u001b[0m )\n\u001b[1;32m--> 125\u001b[0m sgd(\n\u001b[0;32m    126\u001b[0m     params,\n\u001b[0;32m    127\u001b[0m     grads,\n\u001b[0;32m    128\u001b[0m     momentum_buffer_list,\n\u001b[0;32m    129\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    130\u001b[0m     momentum\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    131\u001b[0m     lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    132\u001b[0m     dampening\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdampening\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    133\u001b[0m     nesterov\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnesterov\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    134\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    135\u001b[0m     has_sparse_grad\u001b[38;5;241m=\u001b[39mhas_sparse_grad,\n\u001b[0;32m    136\u001b[0m     foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    137\u001b[0m     fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    138\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    139\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    140\u001b[0m )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# update momentum_buffers in state\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p, momentum_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params, momentum_buffer_list):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\sgd.py:300\u001b[0m, in \u001b[0;36msgd\u001b[1;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, fused, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_sgd\n\u001b[1;32m--> 300\u001b[0m func(\n\u001b[0;32m    301\u001b[0m     params,\n\u001b[0;32m    302\u001b[0m     d_p_list,\n\u001b[0;32m    303\u001b[0m     momentum_buffer_list,\n\u001b[0;32m    304\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    305\u001b[0m     momentum\u001b[38;5;241m=\u001b[39mmomentum,\n\u001b[0;32m    306\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    307\u001b[0m     dampening\u001b[38;5;241m=\u001b[39mdampening,\n\u001b[0;32m    308\u001b[0m     nesterov\u001b[38;5;241m=\u001b[39mnesterov,\n\u001b[0;32m    309\u001b[0m     has_sparse_grad\u001b[38;5;241m=\u001b[39mhas_sparse_grad,\n\u001b[0;32m    310\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    311\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    312\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39mfound_inf,\n\u001b[0;32m    313\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\sgd.py:353\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[1;34m(params, grads, momentum_buffer_list, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    351\u001b[0m         grad \u001b[38;5;241m=\u001b[39m buf\n\u001b[1;32m--> 353\u001b[0m param\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mlr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0, 100000):\n",
    "    # Training pass\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = loss_fn(outputs, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    if i % 1000 == 0: \n",
    "        print(model.bias)\n",
    "        print(model.weight)\n",
    "\n",
    "y_pred = model(X)\n",
    "print(\"y_pred =\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb06f375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[99.7283]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "measurements = torch.tensor([\n",
    "    [37.5]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(measurements)\n",
    "    print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a904b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
